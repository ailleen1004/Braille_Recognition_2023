{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sT57JtpB8QMu"
      },
      "source": [
        "# Mount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THZ5sNQt7eI5",
        "outputId": "9ccfefea-965f-47ae-cd59-c646bf441adf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "import os\n",
        "import sys"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7avyzJ538JJJ"
      },
      "source": [
        "## YOLOv7 Git \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_-HbO317360",
        "outputId": "385d4b3d-698a-4422-e0a8-92020a491244"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 1139, done.\u001b[K\n",
            "remote: Total 1139 (delta 0), reused 0 (delta 0), pack-reused 1139\u001b[K\n",
            "Receiving objects: 100% (1139/1139), 70.41 MiB | 16.59 MiB/s, done.\n",
            "Resolving deltas: 100% (488/488), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/WongKinYiu/yolov7.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n2BvgLX35Wg",
        "outputId": "931ea4a1-b6b9-4a41-9d03-03504373c35d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/braille2023/yolov7\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/braille2023/yolov7\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4SzqzOpe2j5e"
      },
      "source": [
        "# Train Code (Ï†ÑÏù¥ÌïôÏäµ)\n",
        "--weight : Ï†ÑÏù¥ÌïôÏäµÏóê ÏÇ¨Ïö©Ìï† weight ÌååÏùºÍ≤ΩÎ°ú  \n",
        "--data : train set, val setÏùò Í≤ΩÎ°úÏôÄ class ÏÑ§Ï†ï ÌååÏùº Í≤ΩÎ°ú  \n",
        "--hyp : hyper-paramÍ≥º augmentationÏóê ÏÇ¨Ïö©Ìï† param ÌååÏùº Í≤ΩÎ°ú  \n",
        "Ïó¨Í∏∞Ïóê Ïù¥ÎØ∏ÏßÄ Îí§ÏßëÍ∏∞ Í∞íÏùÄ 0ÏúºÎ°ú Î∞îÍøîÏ§òÏïº Ìï®(Ï†êÏûêÍ∞Ä Í≤πÏπ®)  \n",
        "--cfgÎäî Î™®Îç∏Ïùò Íµ¨Ï°∞. ÏÇ¨Ïö©ÌïòÎäî Î™®Îç∏Ïóê Îî∞Îùº Îã§Î•¥Í≤å ÏÑ§Ï†ï.  \n",
        "--name : train Í≥ºÏ†ïÏóêÏÑú ÏÉùÏÑ±ÎêòÎäî ÌååÏùºÎì§Ïùò Ìè¥Îçî Ïù¥Î¶Ñ  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mx21Y-YkX9ox",
        "outputId": "692b5714-2398-44f4-903d-a48012af56d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-06-09 06:47:44.821490: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-09 06:47:45.747345: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "YOLOR üöÄ v0.1-122-g3b41c2c torch 2.0.1+cu118 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Namespace(weights='yolov7-w6_training.pt', cfg='yolov7-w6-custom.yaml', data='custom_data.yaml', hyp='data/hyp.scratch.custom.yaml', epochs=50, batch_size=2, img_size=[1280, 1280], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='runs/train', entity=None, name='yolov7-w6-custom', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', v5_metric=False, freeze=[47], world_size=1, global_rank=-1, save_dir='runs/train/yolov7-w6-custom20', total_batch_size=2)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00125, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, paste_in=0.0, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1         0  models.common.ReOrg                     []                            \n",
            "  1                -1  1      7040  models.common.Conv                      [12, 64, 3, 1]                \n",
            "  2                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  3                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  4                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  5                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 10                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 11                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            " 12                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 13                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 14                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 16                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 17                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 18  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 20                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 22                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 23                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 24                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 25                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 26                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 27  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 28                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 29                -1  1   3540480  models.common.Conv                      [512, 768, 3, 2]              \n",
            " 30                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
            " 31                -2  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
            " 32                -1  1   1327872  models.common.Conv                      [384, 384, 3, 1]              \n",
            " 33                -1  1   1327872  models.common.Conv                      [384, 384, 3, 1]              \n",
            " 34                -1  1   1327872  models.common.Conv                      [384, 384, 3, 1]              \n",
            " 35                -1  1   1327872  models.common.Conv                      [384, 384, 3, 1]              \n",
            " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1   1181184  models.common.Conv                      [1536, 768, 1, 1]             \n",
            " 38                -1  1   7079936  models.common.Conv                      [768, 1024, 3, 2]             \n",
            " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 40                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              \n",
            " 42                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              \n",
            " 43                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              \n",
            " 44                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              \n",
            " 45  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 46                -1  1   2099200  models.common.Conv                      [2048, 1024, 1, 1]            \n",
            " 47                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
            " 48                -1  1    197376  models.common.Conv                      [512, 384, 1, 1]              \n",
            " 49                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 50                37  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
            " 51          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 52                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
            " 53                -2  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
            " 54                -1  1    663936  models.common.Conv                      [384, 192, 3, 1]              \n",
            " 55                -1  1    332160  models.common.Conv                      [192, 192, 3, 1]              \n",
            " 56                -1  1    332160  models.common.Conv                      [192, 192, 3, 1]              \n",
            " 57                -1  1    332160  models.common.Conv                      [192, 192, 3, 1]              \n",
            " 58[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 59                -1  1    590592  models.common.Conv                      [1536, 384, 1, 1]             \n",
            " 60                -1  1     98816  models.common.Conv                      [384, 256, 1, 1]              \n",
            " 61                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 62                28  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 63          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 64                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 65                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 66                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 67                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 68                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 69                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 70[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 71                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 72                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 73                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 74                19  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 75          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 76                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 77                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 78                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 79                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 80                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 81                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 82[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 83                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 84                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            " 85          [-1, 71]  1         0  models.common.Concat                    [1]                           \n",
            " 86                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 87                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 88                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 89                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 90                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 91                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 92[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 93                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 94                -1  1    885504  models.common.Conv                      [256, 384, 3, 2]              \n",
            " 95          [-1, 59]  1         0  models.common.Concat                    [1]                           \n",
            " 96                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
            " 97                -2  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
            " 98                -1  1    663936  models.common.Conv                      [384, 192, 3, 1]              \n",
            " 99                -1  1    332160  models.common.Conv                      [192, 192, 3, 1]              \n",
            "100                -1  1    332160  models.common.Conv                      [192, 192, 3, 1]              \n",
            "101                -1  1    332160  models.common.Conv                      [192, 192, 3, 1]              \n",
            "102[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "103                -1  1    590592  models.common.Conv                      [1536, 384, 1, 1]             \n",
            "104                -1  1   1770496  models.common.Conv                      [384, 512, 3, 2]              \n",
            "105          [-1, 47]  1         0  models.common.Concat                    [1]                           \n",
            "106                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            "107                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            "108                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            "109                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "110                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "111                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "112[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "113                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
            "114                83  1    295424  models.common.Conv                      [128, 256, 3, 1]              \n",
            "115                93  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            "116               103  1   2655744  models.common.Conv                      [384, 768, 3, 1]              \n",
            "117               113  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            "118                83  1    369280  models.common.Conv                      [128, 320, 3, 1]              \n",
            "119                71  1   1475840  models.common.Conv                      [256, 640, 3, 1]              \n",
            "120                59  1   3319680  models.common.Conv                      [384, 960, 3, 1]              \n",
            "121                47  1   5900800  models.common.Conv                      [512, 1280, 3, 1]             \n",
            "122[114, 115, 116, 117, 118, 119, 120, 121]  1    573988  models.yolo.IAuxDetect                  [28, [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], [256, 512, 768, 1024, 320, 640, 960, 1280]]\n",
            "Model Summary: 477 layers, 81412004 parameters, 81412004 gradients\n",
            "\n",
            "Transferred 646/668 items from yolov7-w6_training.pt\n",
            "freezing model.1.conv.weight\n",
            "freezing model.1.bn.weight\n",
            "freezing model.1.bn.bias\n",
            "freezing model.2.conv.weight\n",
            "freezing model.2.bn.weight\n",
            "freezing model.2.bn.bias\n",
            "freezing model.3.conv.weight\n",
            "freezing model.3.bn.weight\n",
            "freezing model.3.bn.bias\n",
            "freezing model.4.conv.weight\n",
            "freezing model.4.bn.weight\n",
            "freezing model.4.bn.bias\n",
            "freezing model.5.conv.weight\n",
            "freezing model.5.bn.weight\n",
            "freezing model.5.bn.bias\n",
            "freezing model.6.conv.weight\n",
            "freezing model.6.bn.weight\n",
            "freezing model.6.bn.bias\n",
            "freezing model.7.conv.weight\n",
            "freezing model.7.bn.weight\n",
            "freezing model.7.bn.bias\n",
            "freezing model.8.conv.weight\n",
            "freezing model.8.bn.weight\n",
            "freezing model.8.bn.bias\n",
            "freezing model.10.conv.weight\n",
            "freezing model.10.bn.weight\n",
            "freezing model.10.bn.bias\n",
            "freezing model.11.conv.weight\n",
            "freezing model.11.bn.weight\n",
            "freezing model.11.bn.bias\n",
            "freezing model.12.conv.weight\n",
            "freezing model.12.bn.weight\n",
            "freezing model.12.bn.bias\n",
            "freezing model.13.conv.weight\n",
            "freezing model.13.bn.weight\n",
            "freezing model.13.bn.bias\n",
            "freezing model.14.conv.weight\n",
            "freezing model.14.bn.weight\n",
            "freezing model.14.bn.bias\n",
            "freezing model.15.conv.weight\n",
            "freezing model.15.bn.weight\n",
            "freezing model.15.bn.bias\n",
            "freezing model.16.conv.weight\n",
            "freezing model.16.bn.weight\n",
            "freezing model.16.bn.bias\n",
            "freezing model.17.conv.weight\n",
            "freezing model.17.bn.weight\n",
            "freezing model.17.bn.bias\n",
            "freezing model.19.conv.weight\n",
            "freezing model.19.bn.weight\n",
            "freezing model.19.bn.bias\n",
            "freezing model.20.conv.weight\n",
            "freezing model.20.bn.weight\n",
            "freezing model.20.bn.bias\n",
            "freezing model.21.conv.weight\n",
            "freezing model.21.bn.weight\n",
            "freezing model.21.bn.bias\n",
            "freezing model.22.conv.weight\n",
            "freezing model.22.bn.weight\n",
            "freezing model.22.bn.bias\n",
            "freezing model.23.conv.weight\n",
            "freezing model.23.bn.weight\n",
            "freezing model.23.bn.bias\n",
            "freezing model.24.conv.weight\n",
            "freezing model.24.bn.weight\n",
            "freezing model.24.bn.bias\n",
            "freezing model.25.conv.weight\n",
            "freezing model.25.bn.weight\n",
            "freezing model.25.bn.bias\n",
            "freezing model.26.conv.weight\n",
            "freezing model.26.bn.weight\n",
            "freezing model.26.bn.bias\n",
            "freezing model.28.conv.weight\n",
            "freezing model.28.bn.weight\n",
            "freezing model.28.bn.bias\n",
            "freezing model.29.conv.weight\n",
            "freezing model.29.bn.weight\n",
            "freezing model.29.bn.bias\n",
            "freezing model.30.conv.weight\n",
            "freezing model.30.bn.weight\n",
            "freezing model.30.bn.bias\n",
            "freezing model.31.conv.weight\n",
            "freezing model.31.bn.weight\n",
            "freezing model.31.bn.bias\n",
            "freezing model.32.conv.weight\n",
            "freezing model.32.bn.weight\n",
            "freezing model.32.bn.bias\n",
            "freezing model.33.conv.weight\n",
            "freezing model.33.bn.weight\n",
            "freezing model.33.bn.bias\n",
            "freezing model.34.conv.weight\n",
            "freezing model.34.bn.weight\n",
            "freezing model.34.bn.bias\n",
            "freezing model.35.conv.weight\n",
            "freezing model.35.bn.weight\n",
            "freezing model.35.bn.bias\n",
            "freezing model.37.conv.weight\n",
            "freezing model.37.bn.weight\n",
            "freezing model.37.bn.bias\n",
            "freezing model.38.conv.weight\n",
            "freezing model.38.bn.weight\n",
            "freezing model.38.bn.bias\n",
            "freezing model.39.conv.weight\n",
            "freezing model.39.bn.weight\n",
            "freezing model.39.bn.bias\n",
            "freezing model.40.conv.weight\n",
            "freezing model.40.bn.weight\n",
            "freezing model.40.bn.bias\n",
            "freezing model.41.conv.weight\n",
            "freezing model.41.bn.weight\n",
            "freezing model.41.bn.bias\n",
            "freezing model.42.conv.weight\n",
            "freezing model.42.bn.weight\n",
            "freezing model.42.bn.bias\n",
            "freezing model.43.conv.weight\n",
            "freezing model.43.bn.weight\n",
            "freezing model.43.bn.bias\n",
            "freezing model.44.conv.weight\n",
            "freezing model.44.bn.weight\n",
            "freezing model.44.bn.bias\n",
            "freezing model.46.conv.weight\n",
            "freezing model.46.bn.weight\n",
            "freezing model.46.bn.bias\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 115 .bias, 115 conv.weight, 115 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/2023_1_Braille_Recognition/2023_data/all_data_split/train/labels' images and labels... 780 found, 0 missing, 0 empty, 0 corrupted:  11% 780/6904 [00:07<00:25, 242.01it/s]\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/drive/MyDrive/2023_1_Braille_Recognition/2023_data/all_data_split/train/images/all_10cm_dr_75degree.jpg: duplicate labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/drive/MyDrive/2023_1_Braille_Recognition/2023_data/all_data_split/train/images/all_10cm_dr_75degree_darker70.jpg: duplicate labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/2023_1_Braille_Recognition/2023_data/all_data_split/train/labels' images and labels... 805 found, 0 missing, 0 empty, 2 corrupted:  12% 805/6904 [00:07<00:25, 238.34it/s]\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/drive/MyDrive/2023_1_Braille_Recognition/2023_data/all_data_split/train/images/all_10cm_dr_75degree_darker80.jpg: duplicate labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/2023_1_Braille_Recognition/2023_data/all_data_split/train/labels' images and labels... 6904 found, 0 missing, 0 empty, 3 corrupted: 100% 6904/6904 [38:03<00:00,  3.02it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/2023_1_Braille_Recognition/2023_data/all_data_split/train/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/2023_1_Braille_Recognition/2023_data/all_data_split/val/labels' images and labels... 192 found, 0 missing, 0 empty, 0 corrupted:  11% 192/1741 [01:41<12:05,  2.14it/s]\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/drive/MyDrive/2023_1_Braille_Recognition/2023_data/all_data_split/val/images/all_10cm_dr_75degree_darker60.jpg: duplicate labels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/2023_1_Braille_Recognition/2023_data/all_data_split/val/labels' images and labels... 193 found, 0 missing, 0 empty, 1 corrupted:  11% 193/1741 [01:41<11:16,  2.29it/s]\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/drive/MyDrive/2023_1_Braille_Recognition/2023_data/all_data_split/val/images/all_10cm_dr_75degree_darker90.jpg: duplicate labels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/2023_1_Braille_Recognition/2023_data/all_data_split/val/labels' images and labels... 1741 found, 0 missing, 0 empty, 2 corrupted: 100% 1741/1741 [11:39<00:00,  2.49it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/2023_1_Braille_Recognition/2023_data/all_data_split/val/labels.cache\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 3.86, Best Possible Recall (BPR) = 0.9908\n",
            "Image sizes 1280 train, 1280 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/yolov7-w6-custom20\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      0/49     3.08G   0.07204   0.04315   0.04117    0.1564        75      1280:  18% 638/3451 [05:01<16:34,  2.83it/s]Premature end of JPEG file\n",
            "      0/49     3.08G   0.07211    0.0429   0.04115    0.1562        57      1280:  19% 652/3451 [05:09<21:57,  2.12it/s]Premature end of JPEG file\n",
            "      0/49     3.08G   0.07213   0.04138    0.0409    0.1544        51      1280:  21% 722/3451 [05:39<19:52,  2.29it/s]Premature end of JPEG file\n",
            "      0/49     3.09G   0.07133   0.03675   0.04078    0.1489         7      1280:  28% 969/3451 [07:27<16:07,  2.56it/s]Premature end of JPEG file\n",
            "      0/49     3.09G   0.06974    0.0312   0.04169    0.1426         2      1280:  43% 1483/3451 [11:11<18:37,  1.76it/s]Premature end of JPEG file\n",
            "      0/49     3.09G   0.06914   0.03009   0.04178     0.141         3      1280:  47% 1612/3451 [12:06<09:17,  3.30it/s]Premature end of JPEG file\n",
            "      0/49     3.09G   0.06848   0.02811   0.04258    0.1392         2      1280:  57% 1955/3451 [14:35<09:31,  2.62it/s]Premature end of JPEG file\n",
            "      0/49     3.09G    0.0658    0.0257    0.0443    0.1358         2      1280:  81% 2790/3451 [20:36<04:01,  2.74it/s]Premature end of JPEG file\n",
            "      0/49      1.7G   0.06307   0.02447   0.04482    0.1324        20      1280: 100% 3451/3451 [25:25<00:00,  2.26it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   0% 0/435 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  59% 257/435 [01:05<00:40,  4.39it/s]Premature end of JPEG file\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 435/435 [01:50<00:00,  3.93it/s]\n",
            "                 all        1739        8938      0.0235       0.156     0.00705     0.00252\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      1/49     3.08G   0.04813    0.0201   0.04158    0.1098         3      1280:   4% 133/3451 [01:04<20:05,  2.75it/s]Premature end of JPEG file\n",
            "      1/49     3.08G   0.04678   0.01781   0.04189    0.1065         2      1280:   8% 279/3451 [02:06<18:35,  2.84it/s]Premature end of JPEG file\n",
            "      1/49     3.08G   0.04737   0.02199   0.04236    0.1117        16      1280:  13% 455/3451 [03:23<17:38,  2.83it/s]Premature end of JPEG file\n",
            "      1/49     3.09G   0.04737   0.02358   0.04225    0.1132         2      1280:  15% 522/3451 [03:53<18:16,  2.67it/s]Premature end of JPEG file\n",
            "      1/49     3.09G   0.04703   0.02393    0.0418    0.1128         3      1280:  19% 639/3451 [04:46<17:46,  2.64it/s]Premature end of JPEG file\n",
            "      1/49     3.09G     0.047   0.02386   0.04173    0.1126        60      1280:  19% 651/3451 [04:51<20:30,  2.28it/s]Premature end of JPEG file\n",
            "      1/49     3.09G   0.04342   0.01829   0.04078    0.1025         4      1280:  47% 1617/3451 [11:48<17:44,  1.72it/s]Premature end of JPEG file\n",
            "      1/49     3.09G   0.04338   0.01829   0.04077    0.1024         5      1280:  47% 1624/3451 [11:50<11:07,  2.74it/s]Premature end of JPEG file\n",
            "      1/49     3.09G   0.04326   0.01814   0.04075    0.1022         5      1280:  49% 1681/3451 [12:13<11:37,  2.54it/s]Premature end of JPEG file\n",
            "      1/49     3.09G   0.04248   0.01763   0.04097    0.1011         1      1280:  58% 1988/3451 [14:28<09:38,  2.53it/s]Premature end of JPEG file\n",
            "      1/49     3.09G   0.04094   0.01655   0.04148   0.09897         2      1280:  82% 2840/3451 [20:29<03:42,  2.74it/s]Premature end of JPEG file\n",
            "      1/49     3.09G   0.04054   0.01627    0.0414   0.09821         1      1280:  89% 3064/3451 [22:03<03:10,  2.04it/s]Premature end of JPEG file\n",
            "      1/49     3.09G   0.03995   0.01582   0.04146   0.09723         4      1280: 100% 3451/3451 [24:47<00:00,  2.32it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  59% 257/435 [01:06<00:52,  3.37it/s]Premature end of JPEG file\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 435/435 [01:52<00:00,  3.86it/s]\n",
            "                 all        1739        8938      0.0351       0.366      0.0261      0.0122\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      2/49      3.9G   0.03646   0.01713    0.0394   0.09299        58      1280:  16% 554/3451 [04:00<15:42,  3.07it/s]Premature end of JPEG file\n",
            "      2/49      3.9G   0.03659   0.01728   0.03927   0.09314        58      1280:  18% 638/3451 [04:37<31:16,  1.50it/s]Premature end of JPEG file\n",
            "      2/49      3.9G   0.03669   0.01724   0.03914   0.09308        30      1280:  19% 653/3451 [04:42<15:09,  3.08it/s]Premature end of JPEG file\n",
            "      2/49      3.9G    0.0353   0.01444   0.03881   0.08855         5      1280:  40% 1376/3451 [09:48<13:57,  2.48it/s]Premature end of JPEG file\n",
            "      2/49      3.9G   0.03507   0.01392   0.03915   0.08813        34      1280:  47% 1605/3451 [11:30<12:53,  2.39it/s]Premature end of JPEG file\n",
            "      2/49      3.9G   0.03457   0.01339   0.03964    0.0876        58      1280:  59% 2022/3451 [14:32<09:19,  2.56it/s]Premature end of JPEG file\n",
            "      2/49      3.9G   0.03454   0.01334   0.03965   0.08753         0      1280:  59% 2050/3451 [14:45<09:55,  2.35it/s]Premature end of JPEG file\n",
            "      2/49      3.9G   0.03327   0.01224   0.04034   0.08585         2      1280: 100% 3451/3451 [24:45<00:00,  2.32it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  59% 256/435 [01:06<00:48,  3.68it/s]Premature end of JPEG file\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 435/435 [01:52<00:00,  3.85it/s]\n",
            "                 all        1739        8938      0.0417       0.373      0.0396      0.0228\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      3/49      3.9G   0.02903   0.01208   0.03802   0.07913        15      1280:   2% 56/3451 [00:27<22:41,  2.49it/s]Premature end of JPEG file\n",
            "      3/49      3.9G   0.03058  0.009668   0.03825    0.0785         2      1280:   8% 279/3451 [02:03<20:38,  2.56it/s]Premature end of JPEG file\n",
            "      3/49      3.9G   0.03283   0.01471   0.03925   0.08679        18      1280:  18% 638/3451 [04:41<19:15,  2.43it/s]Premature end of JPEG file\n",
            "      3/49      3.9G   0.03289   0.01468   0.03922   0.08679        37      1280:  19% 653/3451 [04:47<15:24,  3.03it/s]Premature end of JPEG file\n",
            "      3/49      3.9G   0.03233   0.01421   0.03849   0.08503         5      1280:  24% 844/3451 [06:11<28:44,  1.51it/s]Premature end of JPEG file\n",
            "      3/49      3.9G   0.03135   0.01304   0.03837   0.08276         2      1280:  32% 1096/3451 [08:02<17:36,  2.23it/s]Premature end of JPEG file\n",
            "      3/49      3.9G   0.03095   0.01277   0.03832   0.08203         4      1280:  34% 1185/3451 [08:38<15:25,  2.45it/s]Premature end of JPEG file\n",
            "      3/49      3.9G   0.03057   0.01213   0.03844   0.08114         1      1280:  42% 1444/3451 [10:34<11:58,  2.79it/s]Premature end of JPEG file\n",
            "      3/49      3.9G    0.0296   0.01138   0.03906   0.08004        29      1280:  59% 2033/3451 [14:52<08:26,  2.80it/s]Premature end of JPEG file\n",
            "      3/49      3.9G   0.02952   0.01145   0.03913    0.0801         7      1280:  61% 2089/3451 [15:14<08:37,  2.63it/s]Premature end of JPEG file\n",
            "      3/49      3.9G   0.02797   0.01055   0.03966   0.07817        13      1280: 100% 3436/3451 [24:59<00:07,  2.04it/s]Premature end of JPEG file\n",
            "      3/49      3.9G   0.02795   0.01053   0.03966   0.07814         1      1280: 100% 3451/3451 [25:04<00:00,  2.29it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  59% 257/435 [01:05<00:46,  3.85it/s]Premature end of JPEG file\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 435/435 [01:52<00:00,  3.86it/s]\n",
            "                 all        1739        8938      0.0756       0.281      0.0892      0.0558\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      4/49      3.9G   0.02355  0.007886    0.0368   0.06823         3      1280:   4% 138/3451 [01:02<19:04,  2.89it/s]Premature end of JPEG file\n",
            "      4/49      3.9G   0.02609    0.0136   0.03804   0.07772        43      1280:  19% 639/3451 [04:38<23:28,  2.00it/s]Premature end of JPEG file\n",
            "      4/49      3.9G    0.0262   0.01363   0.03808   0.07792        55      1280:  19% 653/3451 [04:45<18:27,  2.53it/s]Premature end of JPEG file\n",
            "      4/49      3.9G   0.02621   0.01377   0.03799   0.07797        30      1280:  20% 681/3451 [04:58<20:41,  2.23it/s]Premature end of JPEG file\n",
            "      4/49      3.9G   0.02482   0.01137   0.03753   0.07373        19      1280:  44% 1528/3451 [11:02<13:29,  2.38it/s]Premature end of JPEG file\n",
            "      4/49      3.9G   0.02473   0.01116   0.03766   0.07355         2      1280:  47% 1611/3451 [11:36<09:01,  3.40it/s]Premature end of JPEG file\n",
            "      4/49      3.9G   0.02463   0.01104   0.03769   0.07336        24      1280:  49% 1676/3451 [12:04<10:25,  2.84it/s]Premature end of JPEG file\n",
            "      4/49      3.9G   0.02449   0.01088   0.03772   0.07309        17      1280:  51% 1762/3451 [12:40<10:28,  2.69it/s]Premature end of JPEG file\n",
            "      4/49      3.9G   0.02418   0.01046   0.03817   0.07281         4      1280:  66% 2272/3451 [16:21<08:05,  2.43it/s]Premature end of JPEG file\n",
            "      4/49      3.9G   0.02372  0.009658    0.0385   0.07188         1      1280: 100% 3451/3451 [24:45<00:00,  2.32it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  59% 256/435 [01:05<00:40,  4.44it/s]Premature end of JPEG file\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 435/435 [01:52<00:00,  3.87it/s]\n",
            "                 all        1739        8938       0.148         0.3       0.151       0.101\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      5/49      3.9G   0.02298   0.01257   0.03658   0.07213        54      1280:   2% 70/3451 [00:33<23:57,  2.35it/s]Premature end of JPEG file\n",
            "      5/49      3.9G   0.02363   0.01063    0.0368   0.07105        17      1280:   4% 121/3451 [00:55<39:32,  1.40it/s]Premature end of JPEG file\n",
            "      5/49      3.9G   0.02338   0.01315   0.03639   0.07292        30      1280:  18% 638/3451 [04:37<16:14,  2.89it/s]Premature end of JPEG file\n",
            "      5/49      3.9G   0.02347   0.01316   0.03637   0.07301         1      1280:  19% 653/3451 [04:45<27:48,  1.68it/s]Premature end of JPEG file\n",
            "      5/49      3.9G   0.02275   0.01049   0.03612   0.06935         5      1280:  45% 1570/3451 [11:25<13:53,  2.26it/s]Premature end of JPEG file\n",
            "      5/49      3.9G   0.02257   0.01012   0.03609   0.06878         5      1280:  53% 1821/3451 [13:13<11:41,  2.32it/s]Premature end of JPEG file\n",
            "      5/49      3.9G   0.02239  0.009569   0.03639   0.06835        38      1280:  66% 2276/3451 [16:34<08:41,  2.25it/s]Premature end of JPEG file\n",
            "      5/49      3.9G   0.02229  0.009204   0.03641    0.0679        11      1280:  78% 2686/3451 [19:29<07:14,  1.76it/s]Premature end of JPEG file\n",
            "      5/49      3.9G   0.02219  0.009037   0.03643   0.06765         8      1280:  95% 3289/3451 [23:45<01:21,  1.98it/s]Premature end of JPEG file\n",
            "      5/49      3.9G   0.02211  0.008985   0.03645   0.06755         1      1280: 100% 3451/3451 [24:55<00:00,  2.31it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  59% 257/435 [01:06<00:41,  4.26it/s]Premature end of JPEG file\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 435/435 [01:53<00:00,  3.84it/s]\n",
            "                 all        1739        8938       0.332       0.293       0.249        0.17\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      6/49      3.9G   0.02178  0.007849    0.0337   0.06333         2      1280:   6% 190/3451 [01:24<21:50,  2.49it/s]Premature end of JPEG file\n",
            "      6/49      3.9G   0.02253   0.01222   0.03407   0.06882        61      1280:  15% 525/3451 [03:55<27:40,  1.76it/s]Premature end of JPEG file\n",
            "      6/49      3.9G   0.02303   0.01329   0.03452   0.07084        57      1280:  18% 637/3451 [04:44<16:42,  2.81it/s]Premature end of JPEG file\n",
            "      6/49      3.9G   0.02307    0.0133   0.03445   0.07082        35      1280:  19% 651/3451 [04:49<18:09,  2.57it/s]Premature end of JPEG file\n",
            "      6/49      3.9G   0.02298    0.0132   0.03427   0.07045         3      1280:  20% 692/3451 [05:06<19:43,  2.33it/s]Premature end of JPEG file\n",
            "      6/49      3.9G   0.02227   0.01173   0.03367   0.06768         0      1280:  31% 1054/3451 [07:44<14:47,  2.70it/s]Premature end of JPEG file\n",
            "      6/49      3.9G   0.02162  0.009463   0.03378   0.06487         9      1280:  67% 2315/3451 [16:44<07:15,  2.61it/s]Premature end of JPEG file\n",
            "      6/49      3.9G   0.02151  0.009274    0.0338   0.06458         2      1280:  75% 2581/3451 [18:42<05:10,  2.80it/s]Premature end of JPEG file\n",
            "      6/49      3.9G   0.02151  0.009244   0.03379   0.06454         1      1280:  75% 2605/3451 [18:52<08:05,  1.74it/s]Premature end of JPEG file\n",
            "      6/49      3.9G   0.02143  0.009037   0.03376   0.06423         6      1280:  87% 3014/3451 [21:46<02:20,  3.11it/s]Premature end of JPEG file\n",
            "      6/49      3.9G   0.02147  0.008937   0.03373   0.06413         5      1280:  94% 3229/3451 [23:18<01:36,  2.31it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/braille2023/yolov7/train_aux.py\", line 613, in <module>\n",
            "    train(hyp, opt, device, tb_writer)\n",
            "  File \"/content/drive/MyDrive/braille2023/yolov7/train_aux.py\", line 362, in train\n",
            "    loss, loss_items = compute_loss_ota(pred, targets.to(device), imgs)  # loss scaled by batch_size\n",
            "  File \"/content/drive/MyDrive/braille2023/yolov7/utils/loss.py\", line 1205, in __call__\n",
            "    bs_aux, as_aux_, gjs_aux, gis_aux, targets_aux, anchors_aux = self.build_targets2(p[:self.nl], targets, imgs)\n",
            "  File \"/content/drive/MyDrive/braille2023/yolov7/utils/loss.py\", line 1461, in build_targets2\n",
            "    txyxy = xywh2xyxy(txywh)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# 1280ÏùÑ ÏûÖÎ†•ÏúºÎ°ú Î∞õÎäî Î™®Îç∏ÏùÑ ÌïôÏäµÏãúÌÇ§Î†§Î©¥ train_aux.pyÎ°ú Ìï¥ÏïºÌï®, batch 2 learningrate 0.00125, 0.2, freeze backbone\n",
        "!python train_aux.py --workers 8 --device 0 --batch-size 2 --epochs 100 --img 1280 1280 --data custom_data.yaml --hyp data/hyp.scratch.custom.yaml --cfg yolov7-w6-custom.yaml --name yolov7-w6-custom --weights yolov7-w6_training.pt --freeze 47"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8kr_FeCp8CnM"
      },
      "source": [
        "# Detection Code\n",
        "\n",
        "--weightÎ•º ÌÖåÏä§Ìä∏ÌïòÍ≥† Ïã∂ÏùÄ Î™®Îç∏ ÌååÎùºÎØ∏ÌÑ∞ ÌååÏùºÎ°ú Î∞îÍøîÏïº Ìï®"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iISoYL6W782s",
        "outputId": "25c576d4-317b-47a1-e34e-08d418c526d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(weights=['/content/drive/MyDrive/2023_1_Braille_Recognition/result/yolov7-w6-custom/weights/best.pt'], source='detect', img_size=1280, conf_thres=0.1, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n",
            "YOLOR üöÄ v0.1-122-g3b41c2c torch 2.0.1+cu118 CPU\n",
            "\n",
            "Fusing layers... \n",
            "IAuxDetect.fuse\n",
            "Model Summary: 370 layers, 81376868 parameters, 0 gradients\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "3 as, 1 c, 3 is, 1 l, 1 n, 1 o, 2 ps, 1 s, 1 t, 2 uppers, Done. (3682.7ms) Inference, (25.8ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp6/AI_applications.jpg\n",
            "Done. (5.379s)\n"
          ]
        }
      ],
      "source": [
        "!python detect.py --weights /content/drive/MyDrive/2023_1_Braille_Recognition/result/yolov7-w6-custom/weights/best.pt --conf 0.1 --img-size 1280 --source detect"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DK4lrhKYj5Mo"
      },
      "source": [
        "### Export"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "L8_wDJrB38bV"
      },
      "source": [
        "ÏïàÎìúÎ°úÏù¥Îìú Ïä§ÌäúÎîîÏò§ Ïï†ÌîåÎ¶¨ÏºÄÏù¥ÏÖò ÏÉÅÏóêÏÑú Î™®Îç∏ÏùÑ ÏÇ¨Ïö©Ìï† Ïàò ÏûàÎèÑÎ°ù best.pt -> best.ptl ÌååÏùºÎ°ú Î≥ÄÍ≤Ω(export)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19aYExo5lgnI",
        "outputId": "018ca4cd-dc2f-4db0-c6d3-663205f77753"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.22.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.5.0)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.14.0\n"
          ]
        }
      ],
      "source": [
        "!pip install onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-4rOdiRj76o",
        "outputId": "cf688a0f-808a-4604-859b-43fe951fb00f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Import onnx_graphsurgeon failure: No module named 'onnx_graphsurgeon'\n",
            "Namespace(weights='/content/drive/MyDrive/2023_1_Braille_Recognition/result/yolov7-w6-custom/weights/best.pt', img_size=[1280, 1280], batch_size=1, dynamic=False, dynamic_batch=False, grid=True, end2end=True, max_wh=1280, topk_all=100, iou_thres=0.65, conf_thres=0.35, device='cpu', simplify=True, include_nms=False, fp16=False, int8=False)\n",
            "YOLOR üöÄ v0.1-122-g3b41c2c torch 2.0.1+cu118 CPU\n",
            "\n",
            "Fusing layers... \n",
            "IAuxDetect.fuse\n",
            "Model Summary: 370 layers, 81376868 parameters, 0 gradients\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\n",
            "Starting TorchScript export with torch 2.0.1+cu118...\n",
            "/content/drive/MyDrive/braille2023/yolov7/models/yolo.py:374: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if self.grid[i].shape[2:4] != x[i].shape[2:4]:\n",
            "TorchScript export success, saved as /content/drive/MyDrive/2023_1_Braille_Recognition/result/yolov7-w6-custom/weights/best.torchscript.pt\n",
            "CoreML export failure: No module named 'coremltools'\n",
            "\n",
            "Starting TorchScript-Lite export with torch 2.0.1+cu118...\n",
            "TorchScript-Lite export success, saved as /content/drive/MyDrive/2023_1_Braille_Recognition/result/yolov7-w6-custom/weights/best.torchscript.ptl\n",
            "\n",
            "Starting ONNX export with onnx 1.14.0...\n",
            "onnxruntime\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/symbolic_opset9.py:5589: UserWarning: Exporting aten::index operator of advanced indexing in opset 12 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
            "  warnings.warn(\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "Simplifier failure: No module named 'onnxsim'\n",
            "ONNX export success, saved as /content/drive/MyDrive/2023_1_Braille_Recognition/result/yolov7-w6-custom/weights/best.onnx\n",
            "\n",
            "Export complete (52.66s). Visualize with https://github.com/lutzroeder/netron.\n"
          ]
        }
      ],
      "source": [
        "!python export.py --weights /content/drive/MyDrive/2023_1_Braille_Recognition/result/yolov7-w6-custom/weights/best.pt --grid --end2end --simplify --topk-all 100 --iou-thres 0.65 --conf-thres 0.35 --img-size 1280 1280 --max-wh 1280"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuClass": "premium",
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
